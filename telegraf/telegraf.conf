# Telegraf Configuration for Interactive Installation
#
# Telegraf is a data collection agent that gathers system metrics
# and sends them to InfluxDB for monitoring installation infrastructure
# This config monitors: Zone Hubs, Control PC, Network connectivity

# =============================================================================
# GLOBAL SETTINGS
# =============================================================================
# Global tags are added to every metric collected by this Telegraf instance
[global_tags]
  installation = "interactive_installation"  # Identifies our specific installation
  environment = "production"  # Environment type (dev/staging/production)

# =============================================================================
# AGENT CONFIGURATION
# =============================================================================
# Core Telegraf behavior settings
[agent]
  interval = "5s"  # How often to collect metrics
  round_interval = true  # Align collection times to intervals

  # Batching settings for efficient writes
  metric_batch_size = 1000  # Points per batch
  metric_buffer_limit = 10000  # Max points in memory

  # Timing randomization to prevent thundering herd
  collection_jitter = "5s"  # Randomize collection timing
  flush_interval = "10s"  # How often to send batches
  flush_jitter = "5s"  # Randomize flush timing

  # Host identification
  hostname = "control-pc-windows"  # Custom hostname for this agent
  omit_hostname = false  # Include hostname in all metrics

# =============================================================================
# OUTPUT PLUGINS
# =============================================================================
# Define where collected metrics are sent

# InfluxDB v2 output - sends metrics to time-series database
[[outputs.influxdb_v2]]
  urls = ["http://localhost:8086"]  # InfluxDB instance endpoint
  token = "your-influxdb-token"  # Replace with your actual token
  organization = "interactiveInstallation"
  bucket = "system_metrics"  # Separate bucket for infrastructure metrics

  precision = "ns"  # Nanosecond timestamp precision
  timeout = "20s"  # Write timeout

  # Tag-based filtering - only send metrics with these tags
  [outputs.influxdb_v2.tagpass]
    metric_type = ["system", "performance", "network"]

# =============================================================================
# INPUT PLUGINS - SYSTEM METRICS
# =============================================================================
# Input plugins define what metrics to collect

# CPU utilization metrics
[[inputs.cpu]]
  percpu = true  # Individual CPU core stats
  totalcpu = true  # Overall system CPU stats
  collect_cpu_time = false  # Skip raw time values
  report_active = false  # Skip calculated active time

  [inputs.cpu.tags]
    metric_type = "system"  # Category for filtering
    device_category = "control_pc"  # Physical device type

# Memory usage metrics
[[inputs.mem]]
  [inputs.mem.tags]
    metric_type = "system"
    device_category = "control_pc"

# Disk space metrics
[[inputs.disk]]
  # Skip virtual/temporary filesystems
  ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

  [inputs.disk.tags]
    metric_type = "system"
    device_category = "control_pc"

# Disk I/O performance metrics
[[inputs.diskio]]
  [inputs.diskio.tags]
    metric_type = "performance"
    device_category = "control_pc"

# System load averages and uptime
[[inputs.system]]
  fielddrop = ["uptime_format"]  # Skip human-readable uptime

  [inputs.system.tags]
    metric_type = "system"
    device_category = "control_pc"

# Network interface statistics
[[inputs.net]]
  interfaces = ["eth*", "wlan*", "wifi*"]  # Monitor all network interfaces

  [inputs.net.tags]
    metric_type = "network"
    device_category = "control_pc"

# Network connection statistics
[[inputs.netstat]]
  [inputs.netstat.tags]
    metric_type = "network"
    device_category = "control_pc"

# Process monitoring - track specific application performance
[[inputs.procstat]]
  pattern = "python.*installation_sim"  # Monitor installation simulator process

  [inputs.procstat.tags]
    metric_type = "performance"
    device_category = "control_pc"
    process_type = "installation_simulator"

[[inputs.procstat]]
  pattern = "python.*influx_bridge"  # Monitor InfluxDB bridge process

  [inputs.procstat.tags]
    metric_type = "performance"
    device_category = "control_pc"
    process_type = "influx_bridge"

# =============================================================================
# INPUT PLUGINS - CUSTOM INSTALLATION METRICS
# =============================================================================
# Installation-specific monitoring beyond standard system metrics

# HTTP health check monitoring - verify InfluxDB availability
[[inputs.http_response]]
  urls = ["https://influx.g-sdn.com/health"]  # InfluxDB health endpoint
  method = "GET"
  response_timeout = "10s"
  response_string_match = "\"status\":\"pass\""  # Expected healthy response

  [inputs.http_response.tags]
    metric_type = "network"
    device_category = "external_services"
    service_name = "influxdb"

# Network connectivity monitoring - measure latency and packet loss
[[inputs.ping]]
  urls = ["influx.g-sdn.com", "8.8.8.8"]  # Database server + public DNS
  count = 3  # Pings per test
  timeout = 5.0  # Seconds before timeout
  # interface = "eth0"  # Optional: specify network interface

  [inputs.ping.tags]
    metric_type = "network"
    device_category = "connectivity"

# =============================================================================
# INPUT PLUGINS - SIMULATED ZONE HUB METRICS
# =============================================================================
# Simulate metrics from remote microcontrollers using exec plugin

# Zone hub simulation - represents ESP32/Arduino devices in the field
[[inputs.exec]]
  commands = [
    "/usr/bin/python3 /mnt/c/Users/guill/Cloud/Documents/Gsdn/Development/InflulxDB/InteractivArtInstallation/simulate_zone_metrics.py"
  ]
  data_format = "influx"  # Output format expected by Telegraf
  timeout = "10s"  # Script execution timeout
  interval = "30s"  # Run less frequently than main metrics

  [inputs.exec.tags]
    metric_type = "system"
    device_category = "zone_hubs"

# =============================================================================
# PROCESSOR PLUGINS (Optional data transformation)
# =============================================================================
# Transform metrics before sending to output

# Unit conversion for better dashboard readability
[[processors.converter]]
  # Convert byte values to more readable units
  [processors.converter.fields]
    float = ["mem_used", "mem_available", "disk_used", "disk_free"]